{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#                                                   LIBRARIES\n",
    "\n",
    "# Image preprocesssing- processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Neural Network libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "train_animals_reduced = np.load(\"train_animals_reduced.npy\")\n",
    "train_labels_reduced = np.load(\"train_labels_reduced.npy\")\n",
    "test_animals_reduced = np.load(\"test_animals_reduced.npy\")\n",
    "test_labels_reduced = np.load(\"test_labels_reduced.npy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# One hot encoding for labels\n",
    "train_labels_reduced=keras.utils.to_categorical(train_labels_reduced,num_classes)\n",
    "test_labels_reduced=keras.utils.to_categorical(test_labels_reduced,num_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import sequential model and all the required layers\n",
    "def create_model():\n",
    "    #make model\n",
    "    model=Sequential()\n",
    "    # Pairs of Conv2D layer and MaxPool2D Layer with increasing filter sizes ( 16,32 ,64). This helps to make image grow more in depthwise and become more flatten.\n",
    "    # Maxpool: great as they optimize the training time\n",
    "\n",
    "    '''# Pair 1 (16)\n",
    "    model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(50,50,3)))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    # Pair 2 (32)\n",
    "    model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    # Pair 3 (64)\n",
    "    model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    # Dropout layers to reduce overfitting\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "\n",
    "\n",
    "    model.add(Dense(500,activation=\"relu\"))\n",
    "    model.add(Dropout(0.2))'''\n",
    "\n",
    "    # capas de calculo -> ir de menor a mayor, suelen ser potencias / multiplos de 2 (las layers)\n",
    "\n",
    "    model.add(Conv2D(filters=64,kernel_size=3,padding=\"same\",activation=\"relu\",input_shape=(50,50,3))) # parte imp = relu\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    model.add(Conv2D(filters=128,kernel_size=3,padding=\"same\",activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "    model.add(Conv2D(filters=256,kernel_size=3,padding=\"same\",activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=4))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten()) # without flatten output shape = (50, 50, 6) -> flatten = (None, 6) which we need to get layer output\n",
    "\n",
    "\n",
    "    # capas de clasificacion\n",
    "\n",
    "    model.add(Dense(200,activation=\"relu\"))\n",
    "\n",
    "    # Final dense layer with num_classes nodes = categories of animals we have in the set\n",
    "    # Softmax activation is used to give scores to these categories which lie between 0 and 1.\n",
    "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "    model.summary()\n",
    "\n",
    "    # compile the model\n",
    "    # We use loss function as categorical_crossentropy and Adam optimizer\n",
    "\n",
    "    # if binary data -> loss = Binary Cross Entropy and activation = sigmoid\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 50, 50, 64)        1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 25, 25, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 25, 25, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3, 3, 256)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               461000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 603       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 832,419\n",
      "Trainable params: 832,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "6/6 - 1s - loss: 1.4771 - accuracy: 0.8177 - 830ms/epoch - 138ms/step\n",
      "Restored model, accuracy: 81.77%\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.load_weights('model.h5')\n",
    "\n",
    "loss, acc = model.evaluate(test_animals_reduced, test_labels_reduced, verbose=2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}