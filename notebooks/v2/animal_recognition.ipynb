{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Animal Recognition with Neural Networks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Libraries import"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "#                                                   LIBRARIES\n",
    "\n",
    "import os\n",
    "\n",
    "# Dataset\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Image preprocesssing- processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Neural Network libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get Dataset\n",
    "\n",
    "We get the data from a Dataset of Kaggle with different animals images:\n",
    "https://www.kaggle.com/datasets/antoreepjana/animals-detection-images-dataset\n",
    "\n",
    "- Dog\n",
    "- Cat\n",
    "- Zebra\n",
    "- Lion\n",
    "- Leopard\n",
    "- Cheetah\n",
    "- Tiger\n",
    "- Bear\n",
    "- Brown Bear\n",
    "- Butterfly\n",
    "- Canary\n",
    "- Crocodile\n",
    "- Polar Bear\n",
    "- Bull\n",
    "- Camel\n",
    "- Crab\n",
    "- Chicken\n",
    "- Centipede\n",
    "- Cattle\n",
    "- Caterpillar\n",
    "- Duck\n",
    "....\n",
    "- +70 classes (we will use reduced function)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "#                                               PREPARE DATASET\n",
    "#                                            get images from kaggle\n",
    "# kaggle datasets download -d antoreepjana/animals-detection-images-dataset\n",
    "\n",
    "def download_dataset():\n",
    "    # Prepare Kaggle API\n",
    "    os.environ['KAGGLE_USERNAME'] = \"<kaggle-username>\" #\"gruncrow\"\n",
    "    os.environ['KAGGLE_KEY'] = \"<kaggle-api-key>\" #\"ee9f8b0a071cf306b7903a984f9fe492\"\n",
    "\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "\n",
    "    # List files\n",
    "    api.dataset_list_files('antoreepjana/animals-detection-images-dataset').files\n",
    "\n",
    "    # download dataset\n",
    "    api.dataset_download_files('antoreepjana/animals-detection-images-dataset', path=\".\")\n",
    "\n",
    "# load dataset\n",
    "def load_dataset():\n",
    "    dataset = load_dataset(\"arxiv_dataset\", data_dir='./raw_data/', split='train', ignore_verifications=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# Download dataset if it is not downloaded, it will take +- 40 min (10 GB)\n",
    "# download_dataset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare Dataset\n",
    "\n",
    "Transform images to the right format for the model\n",
    "\n",
    "2 arrays:\n",
    "- data: array of images converted to numpy array\n",
    "- labels: corresponding labels\n",
    "    1. Dog\n",
    "    2. Cat\n",
    "    ...\n",
    "    - Zebra\n",
    "    - Lion\n",
    "    - Leopard\n",
    "    - Cheetah\n",
    "    - Tiger\n",
    "    - Bear\n",
    "    - Brown Bear\n",
    "    - Butterfly\n",
    "    - Canary\n",
    "    - Crocodile\n",
    "    - Polar Bear\n",
    "    - Bull\n",
    "    - Camel\n",
    "    - Crab\n",
    "    - Chicken\n",
    "    - Centipede\n",
    "    - Cattle\n",
    "    - Caterpillar\n",
    "    - Duck"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "data=[]\n",
    "# supervised -> labels are needed\n",
    "labels=[]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "#                                           Transform images into an array\n",
    "def load_and_save_all_data(set):\n",
    "    l_data=[]\n",
    "    # supervised -> labels are needed\n",
    "    l_labels=[]\n",
    "\n",
    "    label = 0\n",
    "    train_dir = \"animals-detection-images-dataset\" + os.sep + set\n",
    "    animals_list=os.listdir(train_dir)\n",
    "\n",
    "    # for each animal directory in the dataset directory\n",
    "    for animal in  animals_list:\n",
    "        animal_imgs = os.listdir(\"animals-detection-images-dataset/train/\" + animal)\n",
    "\n",
    "        num_images = 0\n",
    "\n",
    "        # for each image of the current image\n",
    "        # print(animal_dir)\n",
    "        for image in animal_imgs:\n",
    "            # read image\n",
    "            img_dir = train_dir + os.sep + animal + os.sep + image\n",
    "            if os.path.isfile(img_dir):\n",
    "                img=cv2.imread(img_dir)\n",
    "\n",
    "                # convert image to array\n",
    "                img = np.array(img)\n",
    "                img_from_ar = Image.fromarray(img, 'RGB')\n",
    "\n",
    "                # image of same size needed for CNN, ensure they are -> 50X50\n",
    "                resized_image = img_from_ar.resize((50, 50))\n",
    "\n",
    "                # convert back to numpy array\n",
    "                l_data.append(np.array(resized_image))\n",
    "\n",
    "                l_labels.append(label)\n",
    "                num_images += 1\n",
    "\n",
    "\n",
    "        print(\"Label \" + str(label) + \" = \" + str(animal) + \" with \" + str(num_images) + \" images\")\n",
    "\n",
    "\n",
    "        # increment label for next animal\n",
    "        label += 1\n",
    "\n",
    "        # Transform \"normal\" array into numpy array\n",
    "        animals=np.array(l_data)\n",
    "        labels=np.array(l_labels)\n",
    "\n",
    "        # save numpy arrays so manipulation dont need to be done again\n",
    "        np.save(\"animals\",animals)\n",
    "        np.save(\"labels\",labels)\n",
    "\n",
    "def load_data_and_labels():\n",
    "    animals=np.load(\"animals.npy\")\n",
    "    labels=np.load(\"labels.npy\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Reduced:\n",
    "Label 0 = Bear with 87 images\n",
    "Label 1 = Chicken with 388 images\n",
    "Label 2 = Duck with 542 images\n",
    "Label 3 = Frog with 588 images\n",
    "Label 4 = Sea turtle with 239 images\n",
    "Label 5 = Squirrel with 367 images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "train_animals_reduced=[]\n",
    "test_animals_reduced=[]\n",
    "# supervised -> labels are needed\n",
    "train_labels_reduced=[]\n",
    "test_labels_reduced=[]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "#                                           Transform images into an array\n",
    "\n",
    "def load_and_save_data_reduced(set_tt):\n",
    "    assert set_tt == \"test\" or \"train\"\n",
    "    folder_directory = \"\"\n",
    "    if set_tt == \"train\":\n",
    "        folder_directory = \"animals-detection-images-dataset\" + os.sep + \"train\"\n",
    "    elif set_tt == \"test\":\n",
    "        folder_directory = \"animals-detection-images-dataset\" + os.sep + \"test\"\n",
    "    print(\"============= \" + set_tt + \" =============\")\n",
    "    l_data=[]\n",
    "    # supervised -> labels are needed\n",
    "    l_labels=[]\n",
    "\n",
    "    label = 0\n",
    "\n",
    "    animals_list=os.listdir(folder_directory)\n",
    "\n",
    "    # for each animal directory in the dataset directory\n",
    "    for animal in  animals_list:\n",
    "        animals_wanted = [\"Bear\", \"Chicken\", \"Duck\", \"Frog\", \"Sea turtle\",  \"Squirrel\"]\n",
    "\n",
    "        if animal in animals_wanted:\n",
    "            animal_imgs = os.listdir(folder_directory + os.sep + animal)\n",
    "\n",
    "            num_images = 0\n",
    "\n",
    "            # for each image of the current image\n",
    "            # print(animal_dir)\n",
    "            for image in animal_imgs:\n",
    "                # read image\n",
    "                img_dir = folder_directory + os.sep + animal + os.sep + image\n",
    "                if os.path.isfile(img_dir):\n",
    "                    img=cv2.imread(img_dir)\n",
    "\n",
    "                    # convert image to array\n",
    "                    img = np.array(img)\n",
    "                    img_from_ar = Image.fromarray(img, 'RGB')\n",
    "\n",
    "                    # image of same size needed for CNN, ensure they are -> 50X50\n",
    "                    resized_image = img_from_ar.resize((50, 50))\n",
    "\n",
    "                    # convert back to numpy array\n",
    "                    l_data.append(np.array(resized_image))\n",
    "\n",
    "                    l_labels.append(label)\n",
    "                    num_images += 1\n",
    "\n",
    "\n",
    "            print(\"Label \" + str(label) + \" = \" + str(animal) + \" with \" + str(num_images) + \" images\")\n",
    "\n",
    "\n",
    "            # increment label for next animal\n",
    "            label += 1\n",
    "\n",
    "            global train_animals_reduced, train_labels_reduced, test_animals_reduced, test_labels_reduced\n",
    "            # Transform \"normal\" array into numpy array\n",
    "            if set_tt == \"test\":\n",
    "                test_animals_reduced=np.array(l_data)\n",
    "                test_labels_reduced=np.array(l_labels)\n",
    "\n",
    "                # save numpy arrays so manipulation dont need to be done again\n",
    "                np.save(\"test_animals\",test_animals_reduced)\n",
    "                np.save(\"test_labels\",test_labels_reduced)\n",
    "            elif set_tt == \"train\":\n",
    "                train_animals_reduced=np.array(l_data)\n",
    "                train_labels_reduced=np.array(l_labels)\n",
    "\n",
    "                # save numpy arrays so manipulation dont need to be done again\n",
    "                np.save(\"train_animals_reduced\",train_animals_reduced)\n",
    "                np.save(\"train_labels_reduced\",train_labels_reduced)\n",
    "\n",
    "def load_data_and_labels_reduced():\n",
    "    global train_animals_reduced, train_labels_reduced, test_animals_reduced, test_labels_reduced\n",
    "    train_animals_reduced = np.load(\"train_animals.npy\")\n",
    "    train_labels_reduced = np.load(\"train_labels.npy\")\n",
    "    test_animals_reduced = np.load(\"test_animals.npy\")\n",
    "    test_labels_reduced = np.load(\"test_labels.npy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# if its not saved yet:\n",
    "#load_and_save_data_reduced()\n",
    "\n",
    "# if its saved:\n",
    "#load_data_and_labels_reduced()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# load_and_save_data_reduced(\"train\")\n",
    "# load_and_save_data_reduced(\"test\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### ============= train =============\n",
    "Label 0 = Bear with 87 images\n",
    "Label 1 = Chicken with 388 images\n",
    "Label 2 = Duck with 542 images\n",
    "Label 3 = Frog with 588 images\n",
    "Label 4 = Sea turtle with 239 images\n",
    "Label 5 = Squirrel with 367 images\n",
    "\n",
    "#### ============= test =============\n",
    "Label 0 = Bear with 39 images\n",
    "Label 1 = Chicken with 137 images\n",
    "Label 2 = Duck with 88 images\n",
    "Label 3 = Frog with 77 images\n",
    "Label 4 = Sea turtle with 87 images\n",
    "Label 5 = Squirrel with 68 images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "load_data_and_labels_reduced()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# shuffle animals and labels from both sets\n",
    "s=np.arange(train_animals_reduced.shape[0])\n",
    "np.random.shuffle(s)\n",
    "train_animals_reduced=train_animals_reduced[s]\n",
    "train_labels_reduced=train_labels_reduced[s]\n",
    "\n",
    "s=np.arange(test_animals_reduced.shape[0])\n",
    "np.random.shuffle(s)\n",
    "test_animals_reduced=test_animals_reduced[s]\n",
    "test_labels_reduced=test_labels_reduced[s]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data length: 2211\n",
      "Test data length: 496\n"
     ]
    }
   ],
   "source": [
    "# number of classes (labels) and size of dataset\n",
    "num_classes_train=len(np.unique(train_labels_reduced))\n",
    "num_classes_test=len(np.unique(test_labels_reduced))\n",
    "assert num_classes_test == num_classes_train\n",
    "num_classes = num_classes_train\n",
    "\n",
    "train_data_length=len(train_animals_reduced)\n",
    "test_data_length=len(test_animals_reduced)\n",
    "data_length = train_data_length + test_data_length\n",
    "print(\"Train data length: \" + str(train_data_length))\n",
    "print(\"Test data length: \" + str(test_data_length))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train data length: 2211\n",
    "Test data length: 496"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# /255\n",
    "train_animals_reduced = train_animals_reduced.astype('float32')/255\n",
    "test_animals_reduced = test_animals_reduced.astype('float32')/255"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# One hot encoding for labels\n",
    "train_labels_reduced=keras.utils.to_categorical(train_labels_reduced,num_classes_train)\n",
    "test_labels_reduced=keras.utils.to_categorical(test_labels_reduced,num_classes_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Making Keras Model\n",
    "\n",
    "think about hyper parameters like Filter size, number of filters, which type of padding to use, which activatioon functions to use etc."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 50, 50, 16)        208       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 25, 25, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 25, 25, 32)        2080      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 12, 12, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 12, 12, 64)        8256      \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 6, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 6, 6, 64)          0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 500)               1152500   \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 500)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 6)                 3006      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,166,050\n",
      "Trainable params: 1,166,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import sequential model and all the required layers\n",
    "\n",
    "#make model\n",
    "model=Sequential()\n",
    "# Pairs of Conv2D layer and MaxPool2D Layer with increasing filter sizes ( 16,32 ,64). This helps to make image grow more in depthwise and become more flatten.\n",
    "# Maxpool: great as they optimize the training time\n",
    "\n",
    "# Pair 1 (16)\n",
    "model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(50,50,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "# Pair 2 (32)\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "# Pair 3 (64)\n",
    "model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "# Dropout layers to reduce overfitting\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Final dense layer with num_classes nodes = categories of animals we have in the set\n",
    "# Softmax activation is used to give scores to these categories which lie between 0 and 1.\n",
    "model.add(Dense(num_classes,activation=\"softmax\"))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# compile the model\n",
    "# We use loss function as categorical_crossentropy and Adam optimizer\n",
    "\n",
    "# if binary data -> loss = Binary Cross Entropy and activation = sigmoid\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "                  metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "45/45 [==============================] - 1s 32ms/step - loss: 0.3138 - accuracy: 0.8960\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.2616 - accuracy: 0.9177\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.2306 - accuracy: 0.9281\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.2417 - accuracy: 0.9204\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.1750 - accuracy: 0.9507\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.1488 - accuracy: 0.9611\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.1275 - accuracy: 0.9625\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.1288 - accuracy: 0.9625\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 1s 32ms/step - loss: 0.1087 - accuracy: 0.9711\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.1289 - accuracy: 0.9629\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.1262 - accuracy: 0.9625\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.1332 - accuracy: 0.9611\n",
      "Epoch 13/50\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.0970 - accuracy: 0.9751\n",
      "Epoch 14/50\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.0924 - accuracy: 0.9742\n",
      "Epoch 15/50\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.0686 - accuracy: 0.9828\n",
      "Epoch 16/50\n",
      "45/45 [==============================] - 1s 32ms/step - loss: 0.0702 - accuracy: 0.9819\n",
      "Epoch 17/50\n",
      "45/45 [==============================] - 1s 32ms/step - loss: 0.0822 - accuracy: 0.9738\n",
      "Epoch 18/50\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.0682 - accuracy: 0.9792\n",
      "Epoch 19/50\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.0623 - accuracy: 0.9833\n",
      "Epoch 20/50\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.0683 - accuracy: 0.9828\n",
      "Epoch 21/50\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.0898 - accuracy: 0.9747\n",
      "Epoch 22/50\n",
      "45/45 [==============================] - 1s 32ms/step - loss: 0.0857 - accuracy: 0.9751\n",
      "Epoch 23/50\n",
      "45/45 [==============================] - 1s 32ms/step - loss: 0.0993 - accuracy: 0.9688\n",
      "Epoch 24/50\n",
      "45/45 [==============================] - 1s 32ms/step - loss: 0.0700 - accuracy: 0.9796\n",
      "Epoch 25/50\n",
      "45/45 [==============================] - 1s 32ms/step - loss: 0.0636 - accuracy: 0.9833\n",
      "Epoch 26/50\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.0409 - accuracy: 0.9896\n",
      "Epoch 27/50\n",
      "45/45 [==============================] - 1s 29ms/step - loss: 0.0412 - accuracy: 0.9896\n",
      "Epoch 28/50\n",
      "45/45 [==============================] - 1s 29ms/step - loss: 0.0901 - accuracy: 0.9711\n",
      "Epoch 29/50\n",
      "45/45 [==============================] - 1s 29ms/step - loss: 0.0567 - accuracy: 0.9828\n",
      "Epoch 30/50\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0352 - accuracy: 0.9923\n",
      "Epoch 31/50\n",
      "45/45 [==============================] - 1s 29ms/step - loss: 0.0395 - accuracy: 0.9900\n",
      "Epoch 32/50\n",
      "45/45 [==============================] - 1s 29ms/step - loss: 0.0575 - accuracy: 0.9846\n",
      "Epoch 33/50\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0448 - accuracy: 0.9869\n",
      "Epoch 34/50\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0375 - accuracy: 0.9896\n",
      "Epoch 35/50\n",
      "45/45 [==============================] - 1s 32ms/step - loss: 0.0194 - accuracy: 0.9950\n",
      "Epoch 36/50\n",
      "45/45 [==============================] - 1s 29ms/step - loss: 0.0672 - accuracy: 0.9801\n",
      "Epoch 37/50\n",
      "45/45 [==============================] - 1s 29ms/step - loss: 0.1169 - accuracy: 0.9593\n",
      "Epoch 38/50\n",
      "45/45 [==============================] - 1s 29ms/step - loss: 0.1093 - accuracy: 0.9697\n",
      "Epoch 39/50\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.1036 - accuracy: 0.9701\n",
      "Epoch 40/50\n",
      "45/45 [==============================] - 1s 29ms/step - loss: 0.0791 - accuracy: 0.9738\n",
      "Epoch 41/50\n",
      "45/45 [==============================] - 1s 29ms/step - loss: 0.0573 - accuracy: 0.9860\n",
      "Epoch 42/50\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.0371 - accuracy: 0.9891\n",
      "Epoch 43/50\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0320 - accuracy: 0.9878\n",
      "Epoch 44/50\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0426 - accuracy: 0.9878\n",
      "Epoch 45/50\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0477 - accuracy: 0.9860\n",
      "Epoch 46/50\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0522 - accuracy: 0.9837\n",
      "Epoch 47/50\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0435 - accuracy: 0.9855\n",
      "Epoch 48/50\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0644 - accuracy: 0.9787\n",
      "Epoch 49/50\n",
      "45/45 [==============================] - 1s 30ms/step - loss: 0.0426 - accuracy: 0.9873\n",
      "Epoch 50/50\n",
      "45/45 [==============================] - 1s 31ms/step - loss: 0.0421 - accuracy: 0.9851\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x23b86bd49d0>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "model.fit(train_animals_reduced,train_labels_reduced,batch_size=50 ,epochs=50,verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 7ms/step - loss: 3.1589 - accuracy: 0.4819\n",
      "\n",
      " Test accuracy: 0.4818548262119293\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "score = model.evaluate(test_animals_reduced, test_labels_reduced, verbose=1)\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "def convert_to_array(img):\n",
    "    im = cv2.imread(img)\n",
    "    img = Image.fromarray(im, 'RGB')\n",
    "    image = img.resize((50, 50))\n",
    "    return np.array(image)\n",
    "\n",
    "def get_animal_name(label):\n",
    "    if label==0:\n",
    "        return \"Bear\"\n",
    "    if label==1:\n",
    "        return \"Chicken\"\n",
    "    if label==2:\n",
    "        return \"Duck\"\n",
    "    if label==3:\n",
    "        return \"Frog\"\n",
    "    if label==4:\n",
    "        return \"Sea Turtle\"\n",
    "    if label==5:\n",
    "        return \"Squirrel\"\n",
    "\n",
    "def predict_animal(file):\n",
    "    print(\"Predicting .................................\")\n",
    "    ar=convert_to_array(file)\n",
    "    ar=ar/255\n",
    "    label=1\n",
    "    a=[]\n",
    "    a.append(ar)\n",
    "    a=np.array(a)\n",
    "    score=model.predict(a,verbose=1)\n",
    "    print(score)\n",
    "    label_index=np.argmax(score)\n",
    "    print(label_index)\n",
    "    acc=np.max(score)\n",
    "    animal=get_animal_name(label_index)\n",
    "    print(animal)\n",
    "    print(\"The predicted Animal is a \"+animal+\" with accuracy =    \"+str(acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting .................................\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "[[0.12157457 0.11814366 0.1955372  0.19213589 0.21696585 0.1556429 ]]\n",
      "4\n",
      "Sea Turtle\n",
      "The predicted Animal is a Sea Turtle with accuracy =    0.21696585\n"
     ]
    }
   ],
   "source": [
    "# predict image\n",
    "file = \"animals-detection-images-dataset/prediction/duck.jpg\"\n",
    "predict_animal(file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}