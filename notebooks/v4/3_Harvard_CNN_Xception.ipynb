{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from constants import *\n",
    "\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# !pip install tensorflow-addons==0.8.3\n",
    "# !pip install tensorflow==2.2.0-rc3\n",
    "from sklearn.metrics import *\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12177155466809741305\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2249929524\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12419157819836431406\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "gpus"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cpu:0\n"
     ]
    }
   ],
   "source": [
    "device_name = sys.argv[1]  # Choose device from cmd line. Options: gpu or cpu\n",
    "# shape = (int(sys.argv[2]), int(sys.argv[2]))\n",
    "device_name\n",
    "if device_name == \"gpu\":\n",
    "    device_name = \"/gpu:0\"\n",
    "else:\n",
    "    device_name = \"/cpu:0\"\n",
    "\n",
    "print(device_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Paths:\n",
    "# in constants.py file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Variables\n",
    "# in constants.py file # Size of images (images are 200x200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Functions definition\n",
    "#################################################################################\n",
    "\n",
    "def training_function(base, load, weights, optimizer, loss, accuracy, model_name, train_ds, validation_ds, epochs, name_csv_history):\n",
    "  '''\n",
    "  - Function to train a pretrained base model\n",
    "  - To the base model it is added the same classification layer, header\n",
    "\n",
    "  Input:\n",
    "      - base: base model loaded\n",
    "      - load: if = 1 load with weights stored in \"weights\"\n",
    "      - weights: weights of the model, to load if load = 1\n",
    "      - optimizer: model optimizer\n",
    "      - loss: loss function\n",
    "      - accuracy: accuracy variable\n",
    "      - model_name: text string with model name (it will be stored with this name)\n",
    "      - train_ds: training dataset\n",
    "      - validation_ds: validation dataset\n",
    "      - epochs: number of times that the training will be runned of 100 epochs\n",
    "      CANTIDAD DE VECES QUE SE EJECUTAN ENTRENAMIENTOS DE 100 ÉPOCAS\n",
    "      - name_csv_history: text string with the name with which the csv with the training values will be saved, to then graph\n",
    "  '''\n",
    "\n",
    "  # contar el tiempo de ejecución\n",
    "  inicio = time.time()\n",
    "\n",
    "  # confección del modelo\n",
    "  model = tf.keras.Sequential([\n",
    "        base,\n",
    "\n",
    "        tf.keras.layers.GlobalAveragePooling2D(), # se realiza un pooling a los mapas de características de la última capa del modelo base\n",
    "        tf.keras.layers.Dense(128, activation='relu', kernel_initializer='he_uniform'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(64, activation='relu', kernel_initializer='he_uniform'),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(32, activation='relu', kernel_initializer='he_uniform'),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "  model.summary()\n",
    "\n",
    "  # compilación del modelo\n",
    "  model.compile(optimizer = optimizer,loss = loss , metrics = accuracy)\n",
    "\n",
    "  #si load vale 1 se realiza la load de los weights\n",
    "  if load == 1:\n",
    "    model.set_weights(weights)\n",
    "\n",
    "  # callback to save the best model\n",
    "  callback_1 = tf.keras.callbacks.ModelCheckpoint(\n",
    "    os.path.join(MODELS_FOLDER,model_name), monitor='val_categorical_accuracy', verbose=0, save_best_only=True,\n",
    "    save_weights_only=False, mode='max', save_freq='epoch'\n",
    "    )\n",
    "\n",
    "  # callback to stop the model if it hasnt improved in 50 epochs\n",
    "  callback_2 = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_categorical_accuracy', min_delta=0.001, patience=50, verbose=0, mode='max',\n",
    "    baseline=None, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "  # In case it is decided to train more than 100 epochs\n",
    "  for i in range(epochs):\n",
    "\n",
    "    with tf.device('/device:GPU:0'):\n",
    "      h = model.fit(train_ds, epochs= 100, validation_data = validation_ds, batch_size = 2, callbacks= [callback_1, callback_2])\n",
    "\n",
    "    #SECUENCIA PARA CONFECCIÓN DEL CSV\n",
    "    if i > 0:\n",
    "      hist = pd.DataFrame(h.history)\n",
    "      history = pd.concat([history, hist])\n",
    "    else:\n",
    "      history = pd.DataFrame(h.history)\n",
    "\n",
    "  history['epoch'] = list(range(0,len(history.index)))\n",
    "\n",
    "  history.to_csv(os.path.join(CSV_FOLDER, name_csv_history), header=True, index=False)\n",
    "\n",
    "  # Plot history: CE\n",
    "  plt.figure()\n",
    "  plt.plot(history['epoch'], history['loss'], label='Loss (training data)')\n",
    "  plt.plot(history['epoch'], history['val_loss'], label='Loss (validation data)')\n",
    "  plt.title('Loss')\n",
    "  plt.ylabel('CE')\n",
    "  plt.xlabel('Nº epoch')\n",
    "  plt.legend(loc=\"upper left\")\n",
    "  plt.show()\n",
    "\n",
    "  # Plot history: Accuracy\n",
    "  plt.figure()\n",
    "  plt.plot(history['epoch'], history['categorical_accuracy'], label='Accuracy (training data)')\n",
    "  plt.plot(history['epoch'], history['val_categorical_accuracy'], label='Accuracy (validation data)')\n",
    "  plt.title('Accuracy')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.xlabel('Nº epoch')\n",
    "  plt.legend(loc=\"upper left\")\n",
    "  plt.show()\n",
    "\n",
    "  # show training time\n",
    "  fin = time.time()\n",
    "  print(round((fin - inicio)/60, 0))\n",
    "\n",
    "\n",
    "#####################################################\n",
    "\n",
    "def confusion(model, csv):\n",
    "  '''\n",
    "  Function to show the confusion matrix and the classification report of a given model at a csv\n",
    "\n",
    "  Input parameters:\n",
    "    - model: model to be tested\n",
    "    - csv: name of the csv to test the model\n",
    "\n",
    "  Usage example:\n",
    "        model = tf.keras.models.load_model(os.path.join(dir_models, \"Xcep3.h5\"))\n",
    "\n",
    "        confusion(model, 'df_test.csv')\n",
    "\n",
    "  '''\n",
    "\n",
    "  # read csv and create dataframe\n",
    "  csvArray = np.loadtxt((os.path.join(CSV_FOLDER, csv)),dtype=str, delimiter=',', usecols=(0, 1), unpack=True)\n",
    "\n",
    "  imgs_paths = csvArray[:,0]\n",
    "  labels = csvArray[:,1]\n",
    "\n",
    "  # test_panda = pd.read_csv(os.path.join(CSV_FOLDER, csv))\n",
    "\n",
    "  # hago el re escalado con que he trabajado las imágenes\n",
    "  test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                                  rescale=1./255.\n",
    "                                  )\n",
    "\n",
    "  # creo el dataset a partir del dataframe\n",
    "  test_ds = test_datagen.flow_from_dataframe(\n",
    "                        csvArray,\n",
    "                        x_col = 'path',\n",
    "                        y_col = 'clase',\n",
    "                        target_size = (IMG_WIDTH, IMG_HEIGHT),\n",
    "                        color_mode = 'rgb',\n",
    "                        batch_size = 32,\n",
    "                        shuffle = False, # IMPORTANT to dont shuffle so labels will be ordered\n",
    "                        interpolation = \"bicubic\"\n",
    "                        )\n",
    "\n",
    "  # variables to use\n",
    "  y_true = [] # empty list to save the answers\n",
    "  # labels = test_panda['clase'].unique() # class list\n",
    "  unique_labels = set(labels)\n",
    "  num_clases = len(unique_labels)\n",
    "  dictionary = dict(zip(unique_labels, list(range(num_clases)))) # label dictionary and it correspondant number\n",
    "  lista = list(imgs_paths) # list with real values\n",
    "\n",
    "  # predicciones en número\n",
    "  y_pred = np.argmax(model.predict(test_ds), axis=-1)\n",
    "  # llevo las predicciones a texto para poder comparar\n",
    "  for a in lista:\n",
    "    y_true.append(dictionary[a])\n",
    "\n",
    "  # Confusion Matrix\n",
    "  fig, ax = plt.subplots(figsize=(7,7))\n",
    "  conf_matrix = confusion_matrix(y_true, y_pred, labels=np.arange(num_clases))\n",
    "  conf_matrix = conf_matrix/np.sum(conf_matrix, axis=1)\n",
    "  sns.heatmap(conf_matrix, annot=True, fmt=\".2f\", square=True, cbar=False,\n",
    "                cmap=plt.cm.jet, xticklabels=labels, yticklabels=labels,\n",
    "                ax=ax)\n",
    "  ax.set_ylabel('Actual')\n",
    "  ax.set_xlabel('Predicted')\n",
    "  ax.set_title('Confusion Matrix')\n",
    "  plt.show()\n",
    "\n",
    "  # hago el reporte de clasficación\n",
    "  print('Classification Report:')\n",
    "  print(classification_report(y_true, y_pred, labels=np.arange(num_clases), target_names=labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Loss function definition and evaluation function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# A loss object that receives the raw network output and the one-hot raw class labels is created\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "# a metric object that calculates the accuracy is created\n",
    "accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "# optimizer object is created\n",
    "from tensorflow.keras.optimizers import *\n",
    "optimizer1 = Adam(learning_rate=0.01)\n",
    "optimizer2 = Adam(learning_rate=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Preentrenamiento test y validacion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                                  rescale=1./255.\n",
    "                                  )\n",
    "\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                                  rescale=1./255.\n",
    "                                  )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "test_panda = pd.read_csv(os.path.join(CSV_FOLDER, TEST_CSV))\n",
    "valid_panda = pd.read_csv(os.path.join(CSV_FOLDER, VALIDATION_CSV))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# One hot encoding for labels\n",
    "# labels_test = keras.utils.to_categorical(test_panda['class'], 3)\n",
    "# keras.utils.to_categorical(valid_panda['class'], 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               path    class\n0     ../../datasets/animals/final/Turtle_564_4.jpg   Turtle\n1        ../../datasets/animals/final/Turtle_56.jpg   Turtle\n2       ../../datasets/animals/final/Bear_609_3.jpg     Bear\n3       ../../datasets/animals/final/Bear_593_2.jpg     Bear\n4         ../../datasets/animals/final/Turtle_6.jpg   Turtle\n..                                              ...      ...\n907  ../../datasets/animals/final/Chicken_479_1.jpg  Chicken\n908     ../../datasets/animals/final/Bear_635_4.jpg     Bear\n909    ../../datasets/animals/final/Turtle_56_4.jpg   Turtle\n910     ../../datasets/animals/final/Bear_622_2.jpg     Bear\n911  ../../datasets/animals/final/Chicken_481_4.jpg  Chicken\n\n[912 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../../datasets/animals/final/Turtle_564_4.jpg</td>\n      <td>Turtle</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../../datasets/animals/final/Turtle_56.jpg</td>\n      <td>Turtle</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../../datasets/animals/final/Bear_609_3.jpg</td>\n      <td>Bear</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../../datasets/animals/final/Bear_593_2.jpg</td>\n      <td>Bear</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../../datasets/animals/final/Turtle_6.jpg</td>\n      <td>Turtle</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>907</th>\n      <td>../../datasets/animals/final/Chicken_479_1.jpg</td>\n      <td>Chicken</td>\n    </tr>\n    <tr>\n      <th>908</th>\n      <td>../../datasets/animals/final/Bear_635_4.jpg</td>\n      <td>Bear</td>\n    </tr>\n    <tr>\n      <th>909</th>\n      <td>../../datasets/animals/final/Turtle_56_4.jpg</td>\n      <td>Turtle</td>\n    </tr>\n    <tr>\n      <th>910</th>\n      <td>../../datasets/animals/final/Bear_622_2.jpg</td>\n      <td>Bear</td>\n    </tr>\n    <tr>\n      <th>911</th>\n      <td>../../datasets/animals/final/Chicken_481_4.jpg</td>\n      <td>Chicken</td>\n    </tr>\n  </tbody>\n</table>\n<p>912 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_panda"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "'test_np = read_csv(CSV_FOLDER + TEST_CSV)\\nnp.transpose(test_np)\\n\\ntest_imgs = test_np[0]\\ntest_labels = test_np[1]\\ntest_imgs\\nkeras.utils.to_categorical(test_labels, 3)'"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_csv(input_csv):\n",
    "    imgs_relative_path , labels = np.loadtxt(input_csv,dtype=str,\n",
    "                                     delimiter=',', usecols=(0, 1), unpack=True)\n",
    "    return imgs_relative_path, labels\n",
    "\n",
    "'''test_np = read_csv(CSV_FOLDER + TEST_CSV)\n",
    "np.transpose(test_np)\n",
    "\n",
    "test_imgs = test_np[0]\n",
    "test_labels = test_np[1]\n",
    "test_imgs\n",
    "keras.utils.to_categorical(test_labels, 3)'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 912 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_ds = test_datagen.flow_from_dataframe(\n",
    "                        test_panda,\n",
    "                        x_col = 'path',\n",
    "                        y_col = 'class',\n",
    "                        target_size = (IMG_WIDTH,IMG_HEIGHT),\n",
    "                        color_mode = 'rgb',\n",
    "                        batch_size = 32,\n",
    "                        shuffle = True,\n",
    "                        interpolation = \"bicubic\",\n",
    "                        class_mode='categorical'\n",
    "                        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 911 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_ds = valid_datagen.flow_from_dataframe(\n",
    "                        valid_panda,\n",
    "                        x_col = 'path',\n",
    "                        y_col = 'class',\n",
    "                        target_size = (IMG_WIDTH,IMG_HEIGHT),\n",
    "                        color_mode = 'rgb',\n",
    "                        batch_size = 32,\n",
    "                        shuffle = True,\n",
    "                        interpolation = \"bicubic\",\n",
    "                        class_mode='categorical'\n",
    "                        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train generator with data boost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7292 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(CSV_FOLDER, TRAIN_CSV))\n",
    "# keras.utils.to_categorical(train['class'], 3)\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                                  rescale=1./255.,\n",
    "                                  rotation_range = 10,\n",
    "                                  )\n",
    "train_ds = train_datagen.flow_from_dataframe(\n",
    "                        train,\n",
    "                        x_col = 'path',\n",
    "                        y_col = 'class',\n",
    "                        target_size = (IMG_WIDTH,IMG_HEIGHT),\n",
    "                        color_mode = 'rgb',\n",
    "                        batch_size = 128,\n",
    "                        shuffle = True,\n",
    "                        interpolation = \"bicubic\",\n",
    "                        class_mode='categorical'\n",
    "                        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## __Xception (1) Classification Layer training. Frozen base model__"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# base model definition to characteristic extraction\n",
    "# phase 1, frozen model, adjust of classification selection\n",
    "\n",
    "base_model = tf.keras.applications.Xception(input_shape=(IMG_WIDTH, IMG_HEIGHT, 3),\n",
    "                                                include_top=False,\n",
    "                                                weights='imagenet')\n",
    "base_model.trainable = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 7, 7, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               262272    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,134,187\n",
      "Trainable params: 272,707\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "training_function(base_model, 0, 'NOT NECESSARY', optimizer1, loss, accuracy, \"model.h5\", train_ds, valid_ds, 1, \"Xcep1.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " xception (Functional)       (None, 7, 7, 2048)        20861480  \n",
      "                                                                 \n",
      " global_average_pooling2d_5   (None, 2048)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 128)               262272    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,134,187\n",
      "Trainable params: 272,707\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "  # compilación del modelo\n",
    "  # model.compile(optimizer = optimizer,loss = loss , metrics = accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}